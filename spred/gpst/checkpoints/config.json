{
  "afn": "gelu",
  "attn_pdrop": 0.14017714442803875,
  "embd_pdrop": 0.1,
  "finetuning_task": null,
  "initializer_range": 0.02867111594361326,
  "layer_norm_epsilon": 4.1872660376144745e-08,
  "n_ctx": 40,
  "n_embd": 5,
  "n_head": 5,
  "n_layer": 12,
  "n_positions": 40,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "predict_special_tokens": true,
  "resid_pdrop": 0.0831891437060275,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "token_ids",
  "summary_use_proj": true,
  "torchscript": false,
  "vocab_size": 1
}
