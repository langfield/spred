{
  "afn": "gelu",
  "attn_pdrop": 0.06238683350865249,
  "embd_pdrop": 0.1,
  "finetuning_task": null,
  "initializer_range": 0.03329957885480827,
  "layer_norm_epsilon": 3.1143466323710472e-09,
  "n_ctx": 40,
  "n_embd": 5,
  "n_head": 5,
  "n_layer": 12,
  "n_positions": 40,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "predict_special_tokens": true,
  "resid_pdrop": 0.10756727986200348,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "token_ids",
  "summary_use_proj": true,
  "torchscript": false,
  "vocab_size": 1
}
